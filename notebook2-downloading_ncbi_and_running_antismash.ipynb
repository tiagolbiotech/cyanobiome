{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 2 - Downloading NCBI, Running AntiSMASH and Obtaining Metadata\n",
    "\n",
    "This notebook helps to download all cyanobacterial genomes at NCBI and to run antiSMASH for the downloaded genomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading NCBI Genomes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Search for cyanobacteria at [this link here](https://www.ncbi.nlm.nih.gov/Traces/wgs/?page=1&view=all&search=cyanobacteria)\n",
    "- Download spreadsheet using the download button\n",
    "- Upload the file into your server (folder named inputs) and then run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./ncbi_genomes/’: File exists\n",
      "2540\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./inputs/wgs_selector.csv\"):\n",
    "    !mkdir ./ncbi_genomes/\n",
    "    commands = []\n",
    "    count = 0\n",
    "    !cat ./inputs/wgs_selector.csv | tr \"\\t\" \"~\" | cut -d\"~\" -f1 | sed 1d > ./inputs/ids.txt\n",
    "    with open(\"./inputs/ids.txt\") as ids:\n",
    "        for code in ids:\n",
    "            prefix = code.split(',')[0]\n",
    "            count += 1\n",
    "            if not os.path.isfile('./ncbi_genomes/%s.fasta'%prefix):\n",
    "                if '_' in prefix:\n",
    "                    prefix = prefix.split('_')[1]\n",
    "                if len(prefix) > 6:\n",
    "                    line1 = \"wget https://sra-download.ncbi.nlm.nih.gov/traces/wgs01/wgs_aux/%s/%s/%s/%s/%s.1.fsa_nt.gz\"%(prefix[0:2],prefix[2:4],prefix[4:6],prefix,prefix)\n",
    "                    line2 = \"gunzip -c %s.1.fsa_nt.gz > %s.fasta\"%(prefix,prefix)\n",
    "                    commands.append(line1)\n",
    "                    commands.append(line2)\n",
    "                else:\n",
    "                    line1 = \"wget https://sra-download.ncbi.nlm.nih.gov/traces/wgs03/wgs_aux/%s/%s/%s/%s.1.fsa_nt.gz\"%(prefix[0:2],prefix[2:4],prefix,prefix)\n",
    "                    line2 = \"gunzip -c %s.1.fsa_nt.gz > %s.fasta\"%(prefix,prefix)\n",
    "                    commands.append(line1)\n",
    "                    commands.append(line2)\n",
    "    table1_handle = open('./ncbi_genomes/download_cyanobacteria.sh', \"w\")\n",
    "    cmd_df = pd.DataFrame(commands)\n",
    "    cmd_df.to_csv(table1_handle, sep='\\t', index=False, header=False)\n",
    "    table1_handle.close()\n",
    "    !rm ./inputs/ids.txt\n",
    "else:\n",
    "    raise ValueError(\"File ./inputs/wgs_selector.txt not found, please upload the file inside the folder ./inputs/\")\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the selected genomes, run:\n",
    "\n",
    "```bash\n",
    "cd ./ncbi_genomes/\n",
    "\n",
    "sh ./download_cyanobacteria.sh\n",
    "\n",
    "rm *.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2102\n"
     ]
    }
   ],
   "source": [
    "!ls ./ncbi_genomes/*fasta | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing NCBI FASTA Files with Size Zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_list = glob.glob('./ncbi_genomes/*fasta')\n",
    "\n",
    "for item in glob_list:\n",
    "    if os.stat(item).st_size == 0:\n",
    "        cmd = 'rm %s'%item\n",
    "        subprocess.call(cmd,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923\n"
     ]
    }
   ],
   "source": [
    "!ls ./ncbi_genomes/*fasta | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running antiSMASH**\n",
    "\n",
    "https://github.com/mwang87/IOMEGA_Antismash_pipeline\n",
    "\n",
    "To run, your dependencies will be:\n",
    "```\n",
    "docker\n",
    "nextflow - you can install via conda\n",
    "```\n",
    "\n",
    "To actually run:\n",
    "```\n",
    "Put files in to input_sequences folder\n",
    "make run\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtaning Metadata for Table 1 and Dataset S1 (sheet 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error: './ncbi_genomes/PVMC01.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8dcf5ee584d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mgenome_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mgenome_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./ncbi_genomes/%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mgenome_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenome_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mfirst_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'TPA_asm:'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: './ncbi_genomes/PVMC01.fasta'"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqUtils import GC\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "glob_AS = glob.glob('./ncbi_antismash/nf_output/*/')\n",
    "genome_list,taxa_list,fragBGC,compBGC,totalBGC,seen = [],[],[],[],[],[]\n",
    "\n",
    "for AS_path in glob_AS:\n",
    "    genome_file = (AS_path.split('/')[3]).split('_')[0]\n",
    "    genome_list.append(genome_file.split('.')[0])\n",
    "    genome_path = \"./ncbi_genomes/%s\"%genome_file\n",
    "    with open(genome_path) as f:\n",
    "        first_line = f.readline()\n",
    "        if 'TPA_asm:' in str(first_line):\n",
    "            taxa = first_line.split(' ')[2]\n",
    "        if 'uncultured' in str(first_line):\n",
    "            taxa = first_line.split(' ')[2]\n",
    "        if 'TPA_asm:' not in str(first_line) and 'uncultured' not in str(first_line):\n",
    "            taxa = first_line.split(' ')[1]\n",
    "        taxa_list.append(taxa)\n",
    "    glob_BGCs = glob.glob('%s/*region*.gbk'%AS_path)\n",
    "    if glob_BGCs:\n",
    "        frag_count = 0\n",
    "        comp_count = 0\n",
    "        for BGC in glob_BGCs:\n",
    "            input_handle = open(BGC,\"r\")\n",
    "            for record in SeqIO.parse(input_handle,\"genbank\"):\n",
    "                for feat in record.features:\n",
    "                    if feat.type == 'cand_cluster':\n",
    "                        if BGC not in seen:\n",
    "                            seen.append(BGC)\n",
    "                            if str(feat.qualifiers['contig_edge'][0]) == 'True':\n",
    "                                frag_count += 1\n",
    "                            else:\n",
    "                                comp_count += 1\n",
    "        fragBGC.append(frag_count)\n",
    "        compBGC.append(comp_count)\n",
    "        totalBGC.append(frag_count+comp_count)\n",
    "    else:\n",
    "        fragBGC.append(0)\n",
    "        compBGC.append(0)\n",
    "        totalBGC.append(0)\n",
    "    \n",
    "\n",
    "def get_draft_counts(query_genome):\n",
    "    input_handle = open(query_genome,\"r\")\n",
    "    node_count = 0\n",
    "    gc_count = []\n",
    "    for record in SeqIO.parse(input_handle,\"fasta\"):\n",
    "        node_count += 1\n",
    "        gc_count.append(GC(record.seq))\n",
    "    gc_average = np.average(gc_count)\n",
    "    return node_count,gc_average\n",
    "    input_handle.close()\n",
    "\n",
    "node_list,gc_list = [],[]\n",
    "    \n",
    "for genome in genome_list:\n",
    "    node_count,gc_average = get_draft_counts('./ncbi_genomes/%s.fasta'%genome)\n",
    "    node_list.append(node_count)\n",
    "    gc_list.append(gc_average)\n",
    "\n",
    "print(len(genome_list),len(taxa_list),len(node_list),len(gc_list),len(fragBGC),len(compBGC),len(totalBGC))\n",
    "\n",
    "frames = {'GenomeID':genome_list,'Taxa':taxa_list,'Scaffold_count':node_list,\n",
    "         'GC_content':gc_list,'Fragmented_BGCs':fragBGC,'Complete_BGCs':compBGC,\n",
    "         'Total_BGCs':totalBGC}\n",
    "\n",
    "metadata_df = pd.DataFrame(data=frames)\n",
    "\n",
    "# metadata_df.to_csv('cyanobiome_metadata_df-TFL200507.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m./ncbi_genomes/PVMC01.fasta\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./ncbi_genomes/PVMC01.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
